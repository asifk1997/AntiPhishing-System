{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'OpenSSL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9b5692207345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#SELF SIGNED SSL CERTIFICATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mOpenSSL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSSL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mx509\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx509\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNameOID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'OpenSSL'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import display\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *\n",
    "import re\n",
    "import time\n",
    "#SELF SIGNED SSL CERTIFICATE\n",
    "from OpenSSL import SSL\n",
    "from cryptography import x509\n",
    "from cryptography.x509.oid import NameOID\n",
    "import idna\n",
    "\n",
    "from socket import socket\n",
    "from collections import namedtuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\n",
    "        r'^(?:http|ftp)s?://' # http:// or https://\n",
    "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n",
    "        r'localhost|' #localhost...\n",
    "        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "        r'(?::\\d+)?' # optional port\n",
    "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_at_symbol(s):\n",
    "  if \"@\" in s:\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_if_ip(s):\n",
    "  try:\n",
    "    s = s.replace(\"http://\",\"\")\n",
    "    s = s.replace(\"https://\",\"\")\n",
    "    if s.find('/')!=-1 :\n",
    "      index = s.find('/')\n",
    "      s = s[:index]\n",
    "    x = IP(s)\n",
    "    return True\n",
    "  except:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hexadecimal_code(s):\n",
    "  if s.find(\"%\")!=-1:\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_allowed_url_length(s):\n",
    "  if len(s)>35:\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_double_slash_symbol(s):\n",
    "  if s.count(\"//\")>=2:\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_text = {}\n",
    "h_cookie = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page_from_url(url):\n",
    "  # page = urlopen(url)\n",
    "  # html_bytes = page.read()\n",
    "  # html = html_bytes.decode(\"utf-8\")\n",
    "  try:\n",
    "    response = requests.get(url, verify=False)\n",
    "    # print(response.text)\n",
    "    html=response.text\n",
    "    h_text[url] = html\n",
    "    h_cookie[url] = response.cookie\n",
    "  except:\n",
    "    h_text[url] = None\n",
    "    h_cookie[url] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_map(url):\n",
    "  if url in h_text:\n",
    "    return True\n",
    "  else:\n",
    "    parse_page_from_url(url)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_removed_url(s,j):\n",
    "  return s.replace(\".\"+j,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_domain_extensions_from_url(s):\n",
    "  url_components = s.split(\".\")\n",
    "  for i in range(0,len(url_components)):\n",
    "    for j in range(0,len(domain_extension_list)):\n",
    "      # print(i,j)\n",
    "      if url_components[i]==domain_extension_list[j]:\n",
    "        return return_removed_url(s,domain_extension_list[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_domain_name(s):\n",
    "  if s.count(\"https://\")==0:\n",
    "    s = \"https://\"+s\n",
    "  if check_map(s):\n",
    "    html = h_text[s]\n",
    "    if html ==None:\n",
    "      return False\n",
    "    s_after = remove_domain_extensions_from_url(s)\n",
    "    # print(\"s\",s)\n",
    "    if s_after == None:\n",
    "      # print(s)\n",
    "      return False\n",
    "    sa = s_after.split(\".\")\n",
    "\n",
    "    for i in range(0,len(sa)):\n",
    "      if html.find(sa[i])!=-1:\n",
    "        return True\n",
    "    return False\n",
    "  else:\n",
    "    raise ValueError('Parse Page First')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prefix(s):\n",
    "  return check_domain_name(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_form(url):\n",
    "  try:\n",
    "    if url.count('http://')<=0:\n",
    "      url = \"http://\"+url\n",
    "    check_map(url)\n",
    "    html = h_text[url]\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    urls = []\n",
    "    for link in soup.find_all('form'):\n",
    "        # link.get('href')\n",
    "        return True\n",
    "    return False\n",
    "  except:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ FROM CSV TO PANDAS DF\n",
    "domain_extension_list_df = pd.read_csv(\"domain_extension_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_extension_list = []\n",
    "for i in domain_extension_list_df.itertuples():\n",
    "  # print(i[1])\n",
    "  domain_extension_list.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_url_shorteners = [\"goo.gl\",\"bit.ly\",\"owl.ly\",\"deck.ly\",\"bl.ink\"]\n",
    "#abnormal url shortening\n",
    "def abnormal_url_shortening(url):\n",
    "  for i in range(0,len(domain_extension_list)):\n",
    "    # print(domain_extension_list[i])\n",
    "    dom = str(domain_extension_list[i])\n",
    "    \n",
    "    if url.find(dom)!=-1:\n",
    "      return False\n",
    "  # print(\"completed level 1\")\n",
    "  for i in range(0,len(famous_url_shorteners)):\n",
    "    if url.find(famous_url_shorteners[i])!=-1:\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_links_from_url(url):\n",
    "  reqs = requests.get(url)\n",
    "  soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "  \n",
    "  urls = []\n",
    "  for link in soup.find_all('a'):\n",
    "      print(link.get('href'))\n",
    "      urls.append(link.get('href'))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_extensions = [\"mp4\", \"m4a\", \"m4v\", \"f4v\", \"f4a\", \"m4b\", \"m4r\", \"f4b\", \"mov\" , \"3gp\", \"3gp\", \"3g2\", \"3gpp\",\"mp3\",\"png\",\"jpg\",\"bmp\"]\n",
    "def check_malicious_software_download_extension(url):\n",
    "  try:\n",
    "    if url.count(\"http://\")==0:\n",
    "      url = \"http://\"+url\n",
    "    check_map(url)\n",
    "    html = h_text[url]\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "      \n",
    "    urls = []\n",
    "    for link in soup.find_all('a'):\n",
    "      # print(link.get('href'))\n",
    "      urls.append(link.get('href'))\n",
    "      v = link.get('href')\n",
    "      extension = v.split('.')[-1]\n",
    "      if len(extension)==3:\n",
    "        pass\n",
    "        if extension in known_extensions:\n",
    "          return False\n",
    "        else:\n",
    "          return True\n",
    "      else:\n",
    "        return False\n",
    "  except:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt-get install whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt -y install netbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext=['com', 'uk', 'ac_uk', 'ar', 'at', 'pl', 'be', 'biz', 'br', 'ca', 'cc', 'cl', 'club', 'cn', 'co', 'jp', 'co_jp', 'cz', 'de', 'store', 'download', 'edu', 'education', 'eu', 'fi', 'fr', 'id', 'in_', 'info', 'io', 'ir', 'is_is', 'it', 'kr', 'kz', 'lt', 'ru', 'lv', 'me', 'mobi', 'mx', 'name', 'net', 'ninja', 'se', 'nu', 'nyc', 'nz', 'online', 'org', 'pharmacy', 'press', 'pw', 'rest', 'ru_rf', 'security', 'sh', 'site', 'space', 'tech', 'tel', 'theatre', 'tickets', 'tv', 'us', 'uz', 'video', 'website', 'wiki', 'xyz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_whois = {}\n",
    "def check_whois_map(url):\n",
    "  \n",
    "  if url in h_whois:\n",
    "    return h_whois[url]\n",
    "  else:\n",
    "    try:\n",
    "      # do stuff\n",
    "      domain=whois.query(url)\n",
    "      h_whois[url] = domain\n",
    "    except:\n",
    "      domain = None\n",
    "      h_whois[url] = domain\n",
    "    return domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAge(url):\n",
    "  url= url.replace(\"http://\",\"\")\n",
    "  url= url.replace(\"https://\",\"\")\n",
    "  for i in ext:\n",
    "    #print(i)\n",
    "    if url.find(i)!=-1:\n",
    "      url=url.split('.'+i,1)\n",
    "      url=url[0]\n",
    "      url=url+'.'+i\n",
    "      # print(url)\n",
    "      break\n",
    "  domain=check_whois_map(url)\n",
    "  if domain!=None:\n",
    "    creationdate=domain.creation_date\n",
    "    today_Date=datetime.datetime.today()\n",
    "    day=today_Date.day-creationdate.day\n",
    "    month=today_Date.month-creationdate.month\n",
    "    year=today_Date.year-creationdate.year\n",
    "    age=(year*365)+(month*30)+day\n",
    "    age=age/365\n",
    "#     print('age',age)\n",
    "    return math.floor(age)\n",
    "  else:\n",
    "#     print('age',0)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_age(url):\n",
    "  try:\n",
    "    if url.count('http://')==1:\n",
    "      url = \"http://\"+url\n",
    "    age = getAge(url)\n",
    "    if age < 1:\n",
    "      # print(url,age)\n",
    "      return True\n",
    "    else:\n",
    "      # print(url,age)\n",
    "      return False\n",
    "    \n",
    "  except:\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_port(url):\n",
    "  for word in url.split(':'):\n",
    "   if word.isdigit():\n",
    "      if word!=80:\n",
    "        return True\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blacklisted(url):\n",
    "  url= url.replace(\"http://\",\"\")\n",
    "  url= url.replace(\"https://\",\"\")\n",
    "  for i in ext:\n",
    "    #print(i)\n",
    "    if url.find(i)!=-1:\n",
    "      url=url.split('.'+i,1)\n",
    "      url=url[0]\n",
    "      url=url+'.'+i\n",
    "      # print(url)\n",
    "      break\n",
    "  domain=check_whois_map(url)\n",
    "  if domain!=None:\n",
    "    return False\n",
    "  else:\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pyOpenSSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "HostInfo = namedtuple(field_names='cert hostname peername', typename='HostInfo')\n",
    "\n",
    "def get_certificate(hostname, port):\n",
    "    hostname_idna = idna.encode(hostname)\n",
    "    sock = socket()\n",
    "\n",
    "    sock.connect((hostname, port))\n",
    "    peername = sock.getpeername()\n",
    "    ctx = SSL.Context(SSL.SSLv23_METHOD) # most compatible\n",
    "    ctx.check_hostname = False\n",
    "    ctx.verify_mode = SSL.VERIFY_NONE\n",
    "\n",
    "    sock_ssl = SSL.Connection(ctx, sock)\n",
    "    sock_ssl.set_connect_state()\n",
    "    sock_ssl.set_tlsext_host_name(hostname_idna)\n",
    "    sock_ssl.do_handshake()\n",
    "    cert = sock_ssl.get_peer_certificate()\n",
    "    crypto_cert = cert.to_cryptography()\n",
    "    sock_ssl.close()\n",
    "    sock.close()\n",
    "\n",
    "    return HostInfo(cert=crypto_cert, peername=peername, hostname=hostname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_ssl_map = {}\n",
    "def check_if_self_signed_ssl(url):\n",
    "  if url in h_ssl_map:\n",
    "    return h_ssl_map[url]\n",
    "  try:\n",
    "    # print(url)\n",
    "    url = url.replace(\"http://\",\"\").replace(\"https://\",\"\").replace(\"/\",\"\")\n",
    "    cert = get_certificate(url,443)\n",
    "    if cert.cert.issuer == cert.cert.subject:\n",
    "      h_ssl_map[url] = True\n",
    "      return True\n",
    "    else:\n",
    "      h_ssl_map[url] = False\n",
    "      return False\n",
    "  except:\n",
    "    h_ssl_map[url] = False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_abnormal_cookie_domain(url):\n",
    "  try:\n",
    "    if url.count('http://')<=0:\n",
    "      url = \"http://\" + url\n",
    "    check_map(url)\n",
    "    p = h_cookie[url]\n",
    "    # print(p)\n",
    "    p = str(p)\n",
    "    # print(p)\n",
    "    s2 = p.find('for .')\n",
    "    # print(s2)\n",
    "    s3 = p.find('/', s2)\n",
    "    # print(s3)\n",
    "    p2 = p[s2+5:s3]\n",
    "    # print(p2)\n",
    "    if p2 in url:\n",
    "      return False\n",
    "    else:\n",
    "      return True\n",
    "  except:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(value):\n",
    "  if value == True:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path()\n",
    "filename = 'cybersecuritymodel.sav'\n",
    "loaded_model = pickle.load(open(path/filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_enter = widgets.Text(\n",
    "    \n",
    "    placeholder='Type something',\n",
    "    description='Enter URL:',\n",
    "    disabled=False\n",
    ")\n",
    "btn_run =widgets.Button(description=\"Verify\")\n",
    "# lbl_pred = widgets.Label()\n",
    "out_p1 = widgets.Output()\n",
    "out_calculating = widgets.Output()\n",
    "out_calculating_done = widgets.Output()\n",
    "out_calculating_time = widgets.Output()\n",
    "out_model_inferencing = widgets.Output()\n",
    "out_model_inferencing_done = widgets.Output()\n",
    "out_model_inferencing_time = widgets.Output()\n",
    "out_model_features = widgets.Output()\n",
    "out_model_output = widgets.Output()\n",
    "out_result = widgets.Output()\n",
    "\n",
    "def on_click_verify(change):\n",
    "    out_p1.clear_output()\n",
    "    out_calculating.clear_output()\n",
    "    out_calculating_done.clear_output()\n",
    "    out_calculating_time.clear_output()\n",
    "    out_model_inferencing.clear_output()\n",
    "    out_model_inferencing_done.clear_output()\n",
    "    out_model_inferencing_time.clear_output()\n",
    "    out_model_features.clear_output()\n",
    "    out_model_output.clear_output()\n",
    "    out_result.clear_output()\n",
    "    if re.match(regex, url_enter.value) is None:\n",
    "        with out_result : display(\"Enter correct url (add http://) also\")\n",
    "    else:    \n",
    "        with out_p1 : display(url_enter.value)\n",
    "        with out_calculating : display(\"Calculating\")\n",
    "        start_time = time.time()\n",
    "        lis = get_features(url_enter.value)\n",
    "        total_time = time.time() - start_time\n",
    "        with out_calculating : display(\"Calculating Features Done\")\n",
    "        y1 = \"Calculating Features Time : \"+str(total_time)\n",
    "        with out_calculating_time : display(y1)\n",
    "        with out_calculating : display(\"Model predict start\")\n",
    "        start_time2 = time.time()\n",
    "        res = loaded_model.predict(lis)\n",
    "        with out_calculating : display(\"Model predict Done\")\n",
    "        total_time2 = time.time() - start_time2\n",
    "        y2 = \"Inference Time : \"+str(total_time2)\n",
    "        with out_calculating_time : display(y2)\n",
    "        lis_string = str(lis)\n",
    "        with out_model_features : display(lis)\n",
    "        res_string = str(res)\n",
    "        with out_model_output : display(res_string)\n",
    "#         print(lis)\n",
    "#         print(res)\n",
    "        if res[-1] == 0 :\n",
    "            with out_result : display(\"Result : Benign Website\")\n",
    "       \n",
    "        else:\n",
    "            with out_result : display(\"Result : Phishing Website\")\n",
    "          \n",
    "btn_run.on_click(on_click_verify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(x):\n",
    "    f1 = normalise(check_at_symbol(x))\n",
    "    f2 = normalise(check_if_ip(x))\n",
    "    f3 = normalise(check_hexadecimal_code(x))\n",
    "    f4 = normalise(check_allowed_url_length(x))\n",
    "    f5 = normalise(check_double_slash_symbol(x))\n",
    "    f6 = normalise(check_domain_name(x))\n",
    "    f7 = normalise(check_prefix(x))\n",
    "    f8 = normalise(check_form(x))\n",
    "    f9 = normalise(abnormal_url_shortening(x))\n",
    "    f10 = normalise(check_malicious_software_download_extension(x))\n",
    "    f11 = normalise(check_abnormal_cookie_domain(x))\n",
    "    f12 = normalise(check_age(x))\n",
    "    f13 = normalise(match_port(x))\n",
    "    f14 = normalise(check_if_self_signed_ssl(x))\n",
    "    f15 = normalise(is_blacklisted(x))\n",
    "    lis = []\n",
    "    lis2 = []\n",
    "    lis2.extend([f1, f2, f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15])\n",
    "    lis.append(lis2)\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76e07d0823647de880e9c8dfe8a287a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Enter URL to detect it is phishing URL or not!'), Text(value='', description='Enteâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.VBox([widgets.Label(\"Enter URL to detect it is phishing URL or not!\"),url_enter,btn_run,out_p1,out_calculating,out_calculating_done,out_calculating_time,out_model_inferencing,out_model_inferencing_done,out_model_inferencing_time,out_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
